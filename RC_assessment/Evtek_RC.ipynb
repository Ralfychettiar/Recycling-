{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "491a8603-403e-4bc5-8d58-3c8336cc6dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.morphology import (erosion, dilation, closing, opening,\n",
    "                                area_closing, area_opening)\n",
    "from skimage.measure import label, regionprops, regionprops_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa9ab7ed-9d46-4246-9edc-c1ba3beb2954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ralfy\\Box\\RC\\Yoni\\ralfy_assignment\n"
     ]
    }
   ],
   "source": [
    "print(os.path.dirname(os.path.abspath('Evtek_RC.ipynb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a4e31be-1574-4a5a-aa43-7277c78d3451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = os.path.dirname(os.path.abspath('Evtek_RC.ipynb'))\n",
    "# image_list = []\n",
    "# for filename in glob.glob(p + '\\CameraTop\\*.png'):\n",
    "    \n",
    "#     im = cv2.imread(filename)\n",
    "#     image_list.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bdd14e6-7c54-4251-8042-f84fe93f6026",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = os.path.dirname(os.path.abspath('Evtek_RC.ipynb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e38c619-b5b0-4ed7-ab13-f075e74c1eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "for filename in glob.glob(p + '\\CameraTop\\*.png'):\n",
    "    \n",
    "    im = cv2.imread(filename)\n",
    "    image_list.append(im)\n",
    "\n",
    "    \n",
    "images = image_list.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c31e2164-9559-49f6-9d4b-932115acd5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "exr = []\n",
    "for filename in glob.glob(p + '\\CameraTop\\**.exr'):\n",
    "    \n",
    "    exr_im = cv2.imread(filename,0)\n",
    "    exr.append(exr_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53ec7d61-266b-440e-913d-13ae3f62a57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = [p + r\"\\CameraTop\\main\\cola_b\",p + r\"\\CameraTop\\main\\fanta_b\",p + r\"\\CameraTop\\main\\cherry_c\",p + r\"\\CameraTop\\main\\coke_zero\",\n",
    "             p + r\"\\CameraTop\\main\\mthn_dew\",p + r\"\\CameraTop\\main\\fanta_can\",p + r\"\\CameraTop\\main\\cola_can\"]\n",
    "path = p + r\"\\CameraTop\\separated\"\n",
    "\n",
    "if os.path.isdir(p + \"\\CameraTop\\main\") == False:\n",
    "    os.mkdir(p + \"\\CameraTop\\main\")\n",
    "    \n",
    "\n",
    "if os.path.isdir(path) == False:\n",
    "    os.mkdir(path)\n",
    "\n",
    "for i,val in enumerate(path_list):\n",
    "    \n",
    "    if os.path.isdir(val): \n",
    "        continue\n",
    "    else:\n",
    "        os.mkdir(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1eab45-6fd1-41b0-8889-500d6e5df7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a584ceeb-074d-4d5e-b247-65f34244a67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def popimg(img):\n",
    "    cv2.imshow(\"\",img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    " # exr iamges\n",
    "\n",
    "\n",
    "exr_png = []\n",
    "for id in range(len(exr)):\n",
    "    im_exr = exr[id]\n",
    "    im_exr=im_exr*65535\n",
    "    im_exr[im_exr>65535]=65535\n",
    "    im_exr=np.uint16(im_exr)\n",
    "    exr_png.append(im_exr)\n",
    "    # plt.imshow(im_exr)\n",
    "\n",
    "class Hsv():\n",
    "    def orange(self,img):\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.inRange(hsv,(2, 50, 20), (25, 255, 255) )\n",
    "        area = np.sum(mask == 255)\n",
    "        return area\n",
    "    def light_red(self,img):\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.inRange(hsv,(0, 50, 20), (3, 255, 255) )\n",
    "        area = np.sum(mask == 255)\n",
    "        return area\n",
    "    def dark_red(self,img):\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.inRange(hsv,(170, 40, 20), (200, 255, 255) )\n",
    "        area = np.sum(mask == 255)\n",
    "        return area\n",
    "    def cherry_red(self,img):\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.inRange(hsv,(140, 20, 20), (180, 255, 255) )\n",
    "        area = np.sum(mask == 255)\n",
    "        return area\n",
    "    def green(self,img):\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.inRange(hsv,(40, 50, 20), (80, 255, 255) )\n",
    "        area = np.sum(mask == 255)\n",
    "        return area\n",
    "    def diet(self,img):\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.inRange(hsv,(2, 50, 20), (25, 255, 255) )\n",
    "        area = np.sum(mask == 255)\n",
    "        return area  \n",
    "    \n",
    "def separate(images,expng,path,it,path_list):\n",
    "\n",
    "    painting = images\n",
    "\n",
    "    gray_painting = cv2.cvtColor(images, cv2.COLOR_BGR2GRAY)\n",
    "    # gray_painting = gray_painting[80:990,:]\n",
    "    # imshow(painting)\n",
    "    label_im = label(expng)\n",
    "    regions = regionprops(label_im)\n",
    "    # imshow(label_im)\n",
    "    \n",
    "    properties = ['area','convex_area','bbox_area', 'extent',  \n",
    "              'mean_intensity', 'solidity', 'eccentricity', \n",
    "              'orientation']\n",
    "    pd.DataFrame(regionprops_table(label_im, gray_painting, \n",
    "                 properties=properties))\n",
    "    \n",
    "    masks = []\n",
    "    bbox = []\n",
    "    list_of_index = []\n",
    "    for num, x in enumerate(regions):\n",
    "        area = x.area\n",
    "        convex_area = x.convex_area\n",
    "        if (num>=0 and (area>100) and (convex_area/area <5.55) #1.05\n",
    "        and (convex_area/area >0.95)):\n",
    "            masks.append(regions[num].convex_image)\n",
    "            bbox.append(regions[num].bbox)   \n",
    "            list_of_index.append(num)\n",
    "    count = len(masks)\n",
    "    \n",
    "    # each1 = []\n",
    "    fig, ax = plt.subplots(2, int(count/2))#, figsize=(15,8))\n",
    "    plt.close()\n",
    "    it = it\n",
    "    for axis, box, mask in zip(ax.flatten(), bbox, masks):\n",
    "        red  =  painting[:,:,0][box[0]:box[2], box[1]:box[3]] * mask\n",
    "        green = painting[:,:,1][box[0]:box[2], box[1]:box[3]] * mask\n",
    "        blue  = painting[:,:,2][box[0]:box[2], box[1]:box[3]] * mask\n",
    "        image = np.dstack([red,green,blue])\n",
    "        # each1.append(image)\n",
    "        \n",
    "        os.chdir(path)\n",
    "        name = it\n",
    "        filename = \"%s.png\" % name\n",
    "        cv2.imwrite(filename, image)\n",
    "        it += 1 \n",
    "        # imshow(image)\n",
    "        # axis.imshow(image)\n",
    "        \n",
    "        \n",
    "        #HSV\n",
    "        hsv_range = Hsv()\n",
    "        # color1 = [hsv_range.orange(image),hsv_range.light_red(image),hsv_range.dark_red(image),hsv_range.cherry_red(image),hsv_range.green(image),hsv_range.diet(image)]\n",
    "        color1 = [hsv_range.orange(image),hsv_range.light_red(image),hsv_range.dark_red(image),hsv_range.cherry_red(image),hsv_range.green(image)]\n",
    "        \n",
    "        # print(color1)\n",
    "        max_idx = np.argmax(color1)\n",
    "        # print(max_idx)\n",
    "        \n",
    "        if np.max(color1) >4200:\n",
    "            #fanta bottle / can\n",
    "            if max_idx==0:\n",
    "                if 6000<np.max(color1) <10000:\n",
    "                    cv2.imwrite(os.path.join(path_list[1] , filename), image)\n",
    "\n",
    "                elif np.max(color1)>10500:\n",
    "                    cv2.imwrite(os.path.join(path_list[5] , filename), image)\n",
    "\n",
    "            #cola bottle\n",
    "            elif max_idx == 1:\n",
    "                cv2.imwrite(os.path.join(path_list[0], filename), image)\n",
    "\n",
    "            # cola can\n",
    "            elif max_idx==2:\n",
    "                cv2.imwrite(os.path.join(path_list[6] , filename), image)\n",
    "\n",
    "            # cola cherry bottle\n",
    "            elif max_idx==3:\n",
    "                # os.chdir(path_list[2])\n",
    "                cv2.imwrite(os.path.join(path_list[2] ,filename), image)\n",
    "\n",
    "            # mountain\n",
    "            elif max_idx==4:\n",
    "                # os.chdir(path_list[4])\n",
    "                cv2.imwrite(os.path.join(path_list[4] , filename), image)\n",
    "\n",
    "        # diet cola\n",
    "        else:\n",
    "            # os.chdir(path_list[3])\n",
    "            cv2.imwrite(os.path.join(path_list[3] ,filename), image)\n",
    "        \n",
    "      \n",
    "    return it\n",
    "\n",
    "\n",
    "                           \n",
    "it = 0\n",
    "\n",
    "for idx, value in enumerate(images):\n",
    "    it = separate(images[idx],exr_png[idx],path,it,path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1fcfb2b-e535-4830-b978-f6255b4d1d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense   \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa4a88e8-dded-4710-90d6-20cdbef510ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1583 files belonging to 7 classes.\n",
      "Using 1267 files for training.\n",
      "Found 1583 files belonging to 7 classes.\n",
      "Using 316 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    p + r\"\\CameraTop\\main\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=(28,28),\n",
    "    batch_size=1\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    p + r\"\\CameraTop\\main\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=(28,28),\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6b26ae9-f3d4-4aba-a9f3-07610c4179c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = []\n",
    "ytrain = []\n",
    "\n",
    "xtest = []\n",
    "ytest = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c0555aa-1a41-4b1f-996a-faf9bc95b22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_ds.take(len(train_ds)):\n",
    "    for i in range(1):\n",
    "        xtrain.append((images[i].numpy().astype(\"uint8\")))\n",
    "        ytrain.append(int(labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d0a90f9-5578-470d-815c-c8e1f01441d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in val_ds.take(len(val_ds)):\n",
    "    for i in range(1):\n",
    "        xtest.append((images[i].numpy().astype(\"uint8\")))\n",
    "        ytest.append(int(labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9aa51058-06e3-4ed3-9e42-2205dcf91a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def frame(y):\n",
    "    cherry_c = np.zeros(len(y))\n",
    "    coke_zero =np.zeros(len(y))\n",
    "    cola_b =  np.zeros(len(y))\n",
    "    cola_can = np.zeros(len(y))\n",
    "    fanta_b =  np.zeros(len(y))\n",
    "    fanta_can =  np.zeros(len(y))\n",
    "    mthn_dew =  np.zeros(len(y))\n",
    "\n",
    "    for j,valj in enumerate(y):\n",
    "        if valj == 0:\n",
    "            cherry_c[j] = 1\n",
    "        elif valj==1:\n",
    "            coke_zero[j] = 2\n",
    "        elif valj == 2:\n",
    "            cola_b[j] = 3\n",
    "        elif valj==4:\n",
    "            cola_can[j] = 4\n",
    "        elif valj==5:\n",
    "            fanta_b[j] = 5\n",
    "        elif valj==6:\n",
    "            fanta_can[j] = 6\n",
    "        elif valj==7:\n",
    "            mthn_dew[j] =8\n",
    "\n",
    "    data = {'cherry_c':cherry_c,\n",
    "            'coke_zero':coke_zero,\n",
    "            'cola_b':cola_b,\n",
    "            'cola_can':cola_can,\n",
    "            'fanta_b':fanta_b,\n",
    "            'fanta_can':fanta_can,\n",
    "            'mthn_dew':mthn_dew\n",
    "\n",
    "           }\n",
    "    return data\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(frame(ytrain))\n",
    "df_test = pd.DataFrame(frame(ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39a572a9-8eef-48e3-8d05-a0280c462185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 26, 26, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 12, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 10, 10, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 32)          9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 4, 4, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 4, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               65664     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104,295\n",
      "Trainable params: 103,655\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##Model structure\n",
    "cnn3 = Sequential()\n",
    "#layer 1\n",
    "cnn3.add(keras.layers.Conv2D(32,kernel_size= (3, 3), activation='relu', kernel_initializer='he_normal', input_shape=(28, 28, 3)))\n",
    "cnn3.add(keras.layers.BatchNormalization())\n",
    "\n",
    "#Layer 2\n",
    "cnn3.add(keras.layers.Conv2D(32,kernel_size= (3, 3), activation='relu'))\n",
    "cnn3.add(keras.layers.BatchNormalization())\n",
    "cnn3.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "cnn3.add(keras.layers.Dropout(0.6))\n",
    "\n",
    "#Layer 4\n",
    "cnn3.add(keras.layers.Conv2D(32,kernel_size= (3, 3), activation='relu'))\n",
    "cnn3.add(keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "#Layer 3\n",
    "cnn3.add(keras.layers.Conv2D(32,kernel_size= (3, 3), activation='relu'))\n",
    "cnn3.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "cnn3.add(keras.layers.BatchNormalization())\n",
    "\n",
    "#FC1\n",
    "cnn3.add(keras.layers.Flatten())\n",
    "cnn3.add(Dense(128, activation='relu'))\n",
    "cnn3.add(keras.layers.BatchNormalization())\n",
    "cnn3.add(Dense(64, activation='relu'))\n",
    "cnn3.add(keras.layers.BatchNormalization())\n",
    "cnn3.add(Dense(7, activation='softmax'))        \n",
    "\n",
    "cnn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b918e4ae-6860-4820-8dd8-cb87e7b38d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "317/317 [==============================] - 4s 9ms/step - loss: 6.8102 - accuracy: 0.3496 - val_loss: 9.0508 - val_accuracy: 0.4051\n",
      "Epoch 2/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 9.3589 - accuracy: 0.4743 - val_loss: 7.9900 - val_accuracy: 0.6108\n",
      "Epoch 3/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 17.9975 - accuracy: 0.5154 - val_loss: 26.8403 - val_accuracy: 0.5380\n",
      "Epoch 4/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 21.5898 - accuracy: 0.5296 - val_loss: 12.0518 - val_accuracy: 0.5348\n",
      "Epoch 5/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 36.5749 - accuracy: 0.5225 - val_loss: 10.3860 - val_accuracy: 0.6709\n",
      "Epoch 6/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 51.0436 - accuracy: 0.5185 - val_loss: 7.2415 - val_accuracy: 0.6741\n",
      "Epoch 7/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 58.1185 - accuracy: 0.5241 - val_loss: 15.1990 - val_accuracy: 0.7152\n",
      "Epoch 8/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 71.7303 - accuracy: 0.5485 - val_loss: 13.2940 - val_accuracy: 0.7437\n",
      "Epoch 9/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 91.1365 - accuracy: 0.5391 - val_loss: 38.2834 - val_accuracy: 0.6013\n",
      "Epoch 10/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 91.7357 - accuracy: 0.5493 - val_loss: 10.6161 - val_accuracy: 0.7247\n",
      "Epoch 11/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 113.7946 - accuracy: 0.5485 - val_loss: 23.9833 - val_accuracy: 0.7532\n",
      "Epoch 12/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 144.3475 - accuracy: 0.5391 - val_loss: 31.4118 - val_accuracy: 0.6709\n",
      "Epoch 13/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 175.0596 - accuracy: 0.5130 - val_loss: 10.8764 - val_accuracy: 0.8671\n",
      "Epoch 14/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 165.8827 - accuracy: 0.5549 - val_loss: 20.3947 - val_accuracy: 0.7911\n",
      "Epoch 15/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 186.5930 - accuracy: 0.5383 - val_loss: 18.8308 - val_accuracy: 0.8671\n",
      "Epoch 16/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 198.2568 - accuracy: 0.5383 - val_loss: 49.7812 - val_accuracy: 0.8165\n",
      "Epoch 17/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 231.4296 - accuracy: 0.5556 - val_loss: 32.7223 - val_accuracy: 0.6677\n",
      "Epoch 18/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 270.7120 - accuracy: 0.5588 - val_loss: 21.5499 - val_accuracy: 0.8829\n",
      "Epoch 19/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 257.6079 - accuracy: 0.5556 - val_loss: 20.3965 - val_accuracy: 0.8766\n",
      "Epoch 20/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 261.2999 - accuracy: 0.5493 - val_loss: 41.2879 - val_accuracy: 0.8829\n",
      "Epoch 21/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 340.9502 - accuracy: 0.5580 - val_loss: 34.0247 - val_accuracy: 0.8608\n",
      "Epoch 22/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 368.8921 - accuracy: 0.5612 - val_loss: 27.7508 - val_accuracy: 0.8070\n",
      "Epoch 23/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 422.9633 - accuracy: 0.5699 - val_loss: 47.6175 - val_accuracy: 0.8797\n",
      "Epoch 24/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 426.6145 - accuracy: 0.5588 - val_loss: 48.0133 - val_accuracy: 0.8797\n",
      "Epoch 25/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 446.1114 - accuracy: 0.5525 - val_loss: 49.9525 - val_accuracy: 0.8418\n",
      "Epoch 26/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 425.9193 - accuracy: 0.5699 - val_loss: 39.5801 - val_accuracy: 0.8734\n",
      "Epoch 27/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 517.7545 - accuracy: 0.5683 - val_loss: 48.0878 - val_accuracy: 0.9177\n",
      "Epoch 28/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 501.5624 - accuracy: 0.5833 - val_loss: 118.4118 - val_accuracy: 0.8513\n",
      "Epoch 29/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 543.8334 - accuracy: 0.5738 - val_loss: 66.3608 - val_accuracy: 0.8354\n",
      "Epoch 30/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 555.5941 - accuracy: 0.5722 - val_loss: 74.0748 - val_accuracy: 0.8228\n",
      "Epoch 31/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 567.6775 - accuracy: 0.5785 - val_loss: 171.6936 - val_accuracy: 0.6614\n",
      "Epoch 32/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 652.5656 - accuracy: 0.5754 - val_loss: 66.7108 - val_accuracy: 0.9241\n",
      "Epoch 33/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 746.8633 - accuracy: 0.5754 - val_loss: 113.9058 - val_accuracy: 0.7595\n",
      "Epoch 34/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 782.5605 - accuracy: 0.5596 - val_loss: 113.8820 - val_accuracy: 0.8892\n",
      "Epoch 35/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 669.0198 - accuracy: 0.5785 - val_loss: 93.7448 - val_accuracy: 0.8861\n",
      "Epoch 36/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 703.7095 - accuracy: 0.5706 - val_loss: 188.3642 - val_accuracy: 0.7247\n",
      "Epoch 37/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 863.7593 - accuracy: 0.5722 - val_loss: 135.4292 - val_accuracy: 0.8734\n",
      "Epoch 38/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 868.6831 - accuracy: 0.5809 - val_loss: 163.4315 - val_accuracy: 0.8861\n",
      "Epoch 39/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 791.5947 - accuracy: 0.6014 - val_loss: 131.1074 - val_accuracy: 0.8608\n",
      "Epoch 40/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 1020.1069 - accuracy: 0.5864 - val_loss: 107.8443 - val_accuracy: 0.8924\n",
      "Epoch 41/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 937.5447 - accuracy: 0.5730 - val_loss: 123.9471 - val_accuracy: 0.8481\n",
      "Epoch 42/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 1062.4802 - accuracy: 0.5856 - val_loss: 137.2651 - val_accuracy: 0.9051\n",
      "Epoch 43/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 961.5989 - accuracy: 0.5896 - val_loss: 145.3647 - val_accuracy: 0.8544\n",
      "Epoch 44/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 939.2537 - accuracy: 0.5975 - val_loss: 129.1885 - val_accuracy: 0.9209\n",
      "Epoch 45/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 1101.5253 - accuracy: 0.5864 - val_loss: 173.9739 - val_accuracy: 0.8481\n",
      "Epoch 46/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 1112.4103 - accuracy: 0.5872 - val_loss: 180.1732 - val_accuracy: 0.7975\n",
      "Epoch 47/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 1147.1167 - accuracy: 0.5754 - val_loss: 164.9671 - val_accuracy: 0.8418\n",
      "Epoch 48/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 1264.1086 - accuracy: 0.5896 - val_loss: 209.5133 - val_accuracy: 0.8101\n",
      "Epoch 49/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 1513.8307 - accuracy: 0.5754 - val_loss: 170.1691 - val_accuracy: 0.8291\n",
      "Epoch 50/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 1360.6836 - accuracy: 0.5817 - val_loss: 189.2349 - val_accuracy: 0.8892\n",
      "Epoch 51/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 1462.7196 - accuracy: 0.5880 - val_loss: 177.8407 - val_accuracy: 0.8892\n",
      "Epoch 52/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 1424.3260 - accuracy: 0.5888 - val_loss: 194.9519 - val_accuracy: 0.8987\n",
      "Epoch 53/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 1357.4354 - accuracy: 0.5919 - val_loss: 184.7418 - val_accuracy: 0.9019\n",
      "Epoch 54/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 1443.9838 - accuracy: 0.6038 - val_loss: 243.7461 - val_accuracy: 0.8038\n",
      "Epoch 55/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 1466.2045 - accuracy: 0.6014 - val_loss: 212.3443 - val_accuracy: 0.8671\n",
      "Epoch 56/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 1540.4462 - accuracy: 0.6101 - val_loss: 227.0907 - val_accuracy: 0.8133\n",
      "Epoch 57/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 1635.6552 - accuracy: 0.6046 - val_loss: 224.8492 - val_accuracy: 0.9241\n",
      "Epoch 58/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 1552.5601 - accuracy: 0.5943 - val_loss: 219.0914 - val_accuracy: 0.8829\n",
      "Epoch 59/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 2008.6857 - accuracy: 0.5793 - val_loss: 302.1575 - val_accuracy: 0.9272\n",
      "Epoch 60/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 1833.1453 - accuracy: 0.5896 - val_loss: 413.9843 - val_accuracy: 0.8703\n",
      "Epoch 61/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 1997.7719 - accuracy: 0.5943 - val_loss: 295.4255 - val_accuracy: 0.9177\n",
      "Epoch 62/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 1789.3364 - accuracy: 0.5927 - val_loss: 617.0170 - val_accuracy: 0.7025\n",
      "Epoch 63/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 2322.1199 - accuracy: 0.5817 - val_loss: 522.3128 - val_accuracy: 0.8259\n",
      "Epoch 64/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 2082.7771 - accuracy: 0.5872 - val_loss: 291.0743 - val_accuracy: 0.9082\n",
      "Epoch 65/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 1998.9205 - accuracy: 0.5975 - val_loss: 423.7505 - val_accuracy: 0.7943\n",
      "Epoch 66/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 2109.8308 - accuracy: 0.6140 - val_loss: 312.5952 - val_accuracy: 0.8449\n",
      "Epoch 67/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 2187.4341 - accuracy: 0.5991 - val_loss: 331.2179 - val_accuracy: 0.8386\n",
      "Epoch 68/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 2348.0715 - accuracy: 0.6062 - val_loss: 361.2071 - val_accuracy: 0.8987\n",
      "Epoch 69/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 2245.1064 - accuracy: 0.6030 - val_loss: 416.6932 - val_accuracy: 0.8797\n",
      "Epoch 70/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 2285.1045 - accuracy: 0.5983 - val_loss: 476.1552 - val_accuracy: 0.7690\n",
      "Epoch 71/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 2452.8938 - accuracy: 0.5856 - val_loss: 382.0653 - val_accuracy: 0.8418\n",
      "Epoch 72/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 2242.0027 - accuracy: 0.5998 - val_loss: 510.4645 - val_accuracy: 0.7722\n",
      "Epoch 73/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 2583.8545 - accuracy: 0.6022 - val_loss: 405.2015 - val_accuracy: 0.9209\n",
      "Epoch 74/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 2861.3171 - accuracy: 0.6101 - val_loss: 325.8317 - val_accuracy: 0.8861\n",
      "Epoch 75/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 2566.8857 - accuracy: 0.5912 - val_loss: 376.8080 - val_accuracy: 0.8892\n",
      "Epoch 76/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 2718.3379 - accuracy: 0.6054 - val_loss: 357.3208 - val_accuracy: 0.9272\n",
      "Epoch 77/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 2994.3015 - accuracy: 0.5991 - val_loss: 455.1369 - val_accuracy: 0.9019\n",
      "Epoch 78/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 2993.0540 - accuracy: 0.5864 - val_loss: 608.2025 - val_accuracy: 0.8038\n",
      "Epoch 79/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 2782.3801 - accuracy: 0.6125 - val_loss: 497.7855 - val_accuracy: 0.8829\n",
      "Epoch 80/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 3471.1697 - accuracy: 0.5848 - val_loss: 476.6469 - val_accuracy: 0.8956\n",
      "Epoch 81/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 2448.0432 - accuracy: 0.6054 - val_loss: 522.7962 - val_accuracy: 0.8734\n",
      "Epoch 82/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 2792.4314 - accuracy: 0.6014 - val_loss: 611.7944 - val_accuracy: 0.8703\n",
      "Epoch 83/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 3232.3435 - accuracy: 0.6022 - val_loss: 652.9124 - val_accuracy: 0.8829\n",
      "Epoch 84/100\n",
      "317/317 [==============================] - 3s 11ms/step - loss: 2825.2568 - accuracy: 0.6204 - val_loss: 1759.1119 - val_accuracy: 0.6741\n",
      "Epoch 85/100\n",
      "317/317 [==============================] - 3s 10ms/step - loss: 3209.4834 - accuracy: 0.5959 - val_loss: 525.8990 - val_accuracy: 0.9177\n",
      "Epoch 86/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 3365.3430 - accuracy: 0.6046 - val_loss: 460.5388 - val_accuracy: 0.9335\n",
      "Epoch 87/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 3186.0803 - accuracy: 0.6156 - val_loss: 510.0876 - val_accuracy: 0.9146\n",
      "Epoch 88/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 4070.0281 - accuracy: 0.6030 - val_loss: 687.4771 - val_accuracy: 0.8987\n",
      "Epoch 89/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 3236.0171 - accuracy: 0.6204 - val_loss: 542.5300 - val_accuracy: 0.8797\n",
      "Epoch 90/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 3408.3206 - accuracy: 0.6077 - val_loss: 537.8994 - val_accuracy: 0.8544\n",
      "Epoch 91/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 3532.0403 - accuracy: 0.6133 - val_loss: 567.3778 - val_accuracy: 0.9241\n",
      "Epoch 92/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 3929.4099 - accuracy: 0.6069 - val_loss: 554.0061 - val_accuracy: 0.8924\n",
      "Epoch 93/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 3961.5117 - accuracy: 0.6133 - val_loss: 618.1021 - val_accuracy: 0.8861\n",
      "Epoch 94/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 4390.6543 - accuracy: 0.5904 - val_loss: 967.4913 - val_accuracy: 0.8956\n",
      "Epoch 95/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 3464.9885 - accuracy: 0.6101 - val_loss: 738.6078 - val_accuracy: 0.8766\n",
      "Epoch 96/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 3594.7258 - accuracy: 0.6109 - val_loss: 909.3697 - val_accuracy: 0.9177\n",
      "Epoch 97/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 3782.0552 - accuracy: 0.6243 - val_loss: 721.8705 - val_accuracy: 0.8924\n",
      "Epoch 98/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 3539.1038 - accuracy: 0.6330 - val_loss: 882.6636 - val_accuracy: 0.8956\n",
      "Epoch 99/100\n",
      "317/317 [==============================] - 3s 8ms/step - loss: 4616.0659 - accuracy: 0.6140 - val_loss: 760.9105 - val_accuracy: 0.9146\n",
      "Epoch 100/100\n",
      "317/317 [==============================] - 3s 9ms/step - loss: 3584.1292 - accuracy: 0.6227 - val_loss: 2988.4424 - val_accuracy: 0.6994\n"
     ]
    }
   ],
   "source": [
    "#compiling\n",
    "optim = tf.keras.optimizers.Adam(learning_rate=0.001,name=\"adam\")\n",
    "cnn3.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "fit4 =cnn3.fit(np.array(xtrain),df,batch_size = 4,epochs = 100,validation_data = (np.array(xtest),np.array(df_test)),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb612e1-cf8b-415a-9809-7e4589caad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Accuracy graph')\n",
    "plt.plot(fit4.history['accuracy'])\n",
    "plt.plot(fit4.history['val_accuracy'])\n",
    "plt.ylabel('Train/Test Accuracy')\n",
    "plt.xlabel('No. of Iterations')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "# plt.savefig(\"Accuracy graph base.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a56c5f-2268-4737-9125-7496af845b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46ced57-02d5-4366-a1cc-585b56c4df6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d4d0bb-d476-4165-acb9-1d5bae7d63cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c21a700-ece9-4b6e-b505-33572aae65db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
